{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP6k5PMGdCE+euZmU19kO9q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prismvale/Podcast-highlights/blob/main/31oct.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "!pip install openai-whisper yt-dlp webvtt-py transformers torch gradio --quiet\n",
        "\n",
        "# ==============================\n",
        "# üé• AI-Powered Auto Clip Generator (Colab + Gradio Frontend)\n",
        "# ==============================\n",
        "import os\n",
        "import re\n",
        "import subprocess\n",
        "import yt_dlp\n",
        "import whisper\n",
        "import webvtt\n",
        "import gradio as gr\n",
        "from transformers import pipeline\n",
        "\n",
        "# ==============================\n",
        "# ‚öôÔ∏è Core Logic Function\n",
        "# ==============================\n",
        "def process_youtube_video(url):\n",
        "    try:\n",
        "        # ---------- CLEANUP ----------\n",
        "        patterns = [\"video.mp4\", \"video.en.vtt\", \"clip_.*\\.mp4\", \"clip_.*\\.vtt\"]\n",
        "        for pattern in patterns:\n",
        "            for file in [f for f in os.listdir() if re.fullmatch(pattern.replace(\"*\", \".*\"), f)]:\n",
        "                try:\n",
        "                    os.remove(file)\n",
        "                except Exception:\n",
        "                    pass\n",
        "\n",
        "        video_file = \"video.mp4\"\n",
        "        sub_file = \"video.en.vtt\"\n",
        "\n",
        "        # ---------- DOWNLOAD ----------\n",
        "        ydl_opts = {\"format\": \"mp4\", \"outtmpl\": \"video.%(ext)s\"}\n",
        "        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "            ydl.download([url])\n",
        "\n",
        "        # ---------- WHISPER ----------\n",
        "        model = whisper.load_model(\"tiny\")\n",
        "        result = model.transcribe(video_file)\n",
        "\n",
        "        with open(sub_file, \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(\"WEBVTT\\n\\n\")\n",
        "            for i, seg in enumerate(result[\"segments\"]):\n",
        "                start, end, text = seg[\"start\"], seg[\"end\"], seg[\"text\"].strip()\n",
        "                def sec_to_vtt(s):\n",
        "                    h = int(s // 3600)\n",
        "                    m = int((s % 3600) // 60)\n",
        "                    sec = s % 60\n",
        "                    return f\"{h:02}:{m:02}:{sec:06.3f}\"\n",
        "                f.write(f\"{i+1}\\n{sec_to_vtt(start)} --> {sec_to_vtt(end)}\\n{text}\\n\\n\")\n",
        "\n",
        "        # ---------- GROUP CHUNKS ----------\n",
        "        grouped_chunks = []\n",
        "        current_chunk, chunk_start, chunk_end = [], None, None\n",
        "        max_chunk_duration, min_chunk_duration = 25.0, 10.0\n",
        "\n",
        "        for caption in webvtt.read(sub_file):\n",
        "            start_sec = sum(float(x) * 60 ** i for i, x in enumerate(reversed(caption.start.split(\":\"))))\n",
        "            end_sec = sum(float(x) * 60 ** i for i, x in enumerate(reversed(caption.end.split(\":\"))))\n",
        "\n",
        "            if chunk_start is None:\n",
        "                chunk_start = start_sec\n",
        "\n",
        "            sentences = [s.strip() for s in re.split(r'(?<=[.!?]) +', caption.text) if s.strip()]\n",
        "\n",
        "            for sentence in sentences:\n",
        "                current_chunk.append(sentence)\n",
        "                chunk_end = end_sec\n",
        "                if chunk_start is not None and chunk_end is not None and (chunk_end - chunk_start >= max_chunk_duration):\n",
        "                    if grouped_chunks and (chunk_end - chunk_start < min_chunk_duration):\n",
        "                        grouped_chunks[-1][\"end\"] = chunk_end\n",
        "                        grouped_chunks[-1][\"text\"] += \" \" + \" \".join(current_chunk)\n",
        "                    else:\n",
        "                        grouped_chunks.append({\n",
        "                            \"start\": chunk_start,\n",
        "                            \"end\": chunk_end,\n",
        "                            \"text\": \" \".join(current_chunk)\n",
        "                        })\n",
        "                    current_chunk, chunk_start, chunk_end = [], None, None\n",
        "\n",
        "        if current_chunk:\n",
        "            if chunk_start is not None and chunk_end is not None:\n",
        "                if grouped_chunks and (chunk_end - chunk_start < min_chunk_duration):\n",
        "                    grouped_chunks[-1][\"end\"] = chunk_end\n",
        "                    grouped_chunks[-1][\"text\"] += \" \" + \" \".join(current_chunk)\n",
        "                else:\n",
        "                    grouped_chunks.append({\n",
        "                        \"start\": chunk_start,\n",
        "                        \"end\": chunk_end,\n",
        "                        \"text\": \" \".join(current_chunk)\n",
        "                    })\n",
        "\n",
        "        # ---------- ANALYSIS ----------\n",
        "        sentiment_model = pipeline(\"sentiment-analysis\", model=\"cardiffnlp/twitter-roberta-base-sentiment\")\n",
        "        emotion_model = pipeline(\"text-classification\",\n",
        "                                 model=\"joeddav/distilbert-base-uncased-go-emotions-student\",\n",
        "                                 return_all_scores=True)\n",
        "\n",
        "        scored_chunks = []\n",
        "        for chunk in grouped_chunks:\n",
        "            text = chunk[\"text\"]\n",
        "            sentiment = sentiment_model(text[:512])[0]\n",
        "            emotions = emotion_model(text[:512])[0]\n",
        "            top_emotion = max(emotions, key=lambda x: x['score'])\n",
        "            score = sentiment['score'] * 5\n",
        "            if top_emotion['label'] in [\"joy\", \"excitement\", \"anger\", \"sadness\"]:\n",
        "                score += top_emotion['score'] * 5\n",
        "            scored_chunks.append({\n",
        "                \"start\": chunk[\"start\"],\n",
        "                \"end\": chunk[\"end\"],\n",
        "                \"text\": text,\n",
        "                \"sentiment\": sentiment['label'],\n",
        "                \"emotion\": top_emotion['label'],\n",
        "                \"score\": score\n",
        "            })\n",
        "\n",
        "        # ---------- SELECT TOP 3 ----------\n",
        "        scored_chunks = sorted(scored_chunks, key=lambda x: x[\"score\"], reverse=True)\n",
        "        top3 = scored_chunks[:3]\n",
        "\n",
        "        result_text = \"üî• **Top 3 Engaging Moments:**\\n\\n\"\n",
        "        #for i, c in enumerate(top3, 1):\n",
        "            #result_text += f\"### üé¨ Clip {i}\\n\"\n",
        "            #result_text += f\"- Time: {c['start']:.2f}s ‚Üí {c['end']:.2f}s\\n\"\n",
        "            #result_text += f\"- Emotion: {c['emotion']} | Sentiment: {c['sentiment']} | Score: {c['score']:.2f}\\n\"\n",
        "            #result_text += f\"- Text: {c['text'][:150]}...\\n\\n\"\n",
        "\n",
        "        # ---------- EXTRACT CLIPS ----------\n",
        "        captions = list(webvtt.read(sub_file))\n",
        "        def format_time(seconds):\n",
        "            h = int(seconds // 3600)\n",
        "            m = int((seconds % 3600) // 60)\n",
        "            s = seconds % 60\n",
        "            return f\"{h:02d}:{m:02d}:{s:06.3f}\".replace('.', ',')\n",
        "\n",
        "        video_files = []\n",
        "        for i, clip in enumerate(top3, 1):\n",
        "            start, end = clip[\"start\"], clip[\"end\"]\n",
        "            out_video, out_sub = f\"clip_{i}.mp4\", f\"clip_{i}.vtt\"\n",
        "            cmd = [\"ffmpeg\", \"-y\", \"-i\", video_file, \"-ss\", str(start), \"-to\", str(end), \"-c\", \"copy\", out_video]\n",
        "            subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "            video_files.append(out_video)\n",
        "\n",
        "            selected = []\n",
        "            for c in captions:\n",
        "                start_sec = sum(float(x) * 60 ** i for i, x in enumerate(reversed(c.start.split(\":\"))))\n",
        "                end_sec = sum(float(x) * 60 ** i for i, x in enumerate(reversed(c.end.split(\":\"))))\n",
        "                if start_sec >= start and end_sec <= end:\n",
        "                    new_start, new_end = start_sec - start, end_sec - start\n",
        "                    selected.append(f\"{format_time(new_start)} --> {format_time(new_end)}\\n{c.text}\\n\")\n",
        "\n",
        "            with open(out_sub, \"w\", encoding=\"utf-8\") as f:\n",
        "                f.write(\"WEBVTT\\n\\n\" + \"\\n\".join(selected))\n",
        "\n",
        "        return result_text, video_files[0] if len(video_files) > 0 else None, video_files[1] if len(video_files) > 1 else None, video_files[2] if len(video_files) > 2 else None\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"‚ö†Ô∏è Error: {e}\", None, None, None\n",
        "\n",
        "# ==============================\n",
        "# üé® Gradio UI\n",
        "# ==============================\n",
        "demo = gr.Interface(\n",
        "    fn=process_youtube_video,\n",
        "    inputs=gr.Textbox(label=\"Enter YouTube URL\"),\n",
        "    outputs=[\n",
        "        gr.Markdown(label=\"Results\"),\n",
        "        gr.Video(label=\"Clip 1\"),\n",
        "        gr.Video(label=\"Clip 2\"),\n",
        "        gr.Video(label=\"Clip 3\")\n",
        "    ],\n",
        "    title=\"üé• AI Auto Clip Generator\",\n",
        "    description=\"Automatically extracts top 3 emotional or engaging clips from a YouTube video using Whisper + NLP sentiment/emotion analysis.\",\n",
        "    allow_flagging=\"never\"\n",
        ")\n",
        "\n",
        "demo.launch(debug=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "cellView": "form",
        "id": "WlCzDHDyClYs",
        "outputId": "360b9c47-7a82-4bed-9941-5665c310c83a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:22: SyntaxWarning: invalid escape sequence '\\.'\n",
            "<>:22: SyntaxWarning: invalid escape sequence '\\.'\n",
            "<>:22: SyntaxWarning: invalid escape sequence '\\.'\n",
            "<>:22: SyntaxWarning: invalid escape sequence '\\.'\n",
            "/tmp/ipython-input-98566741.py:22: SyntaxWarning: invalid escape sequence '\\.'\n",
            "  patterns = [\"video.mp4\", \"video.en.vtt\", \"clip_.*\\.mp4\", \"clip_.*\\.vtt\"]\n",
            "/tmp/ipython-input-98566741.py:22: SyntaxWarning: invalid escape sequence '\\.'\n",
            "  patterns = [\"video.mp4\", \"video.en.vtt\", \"clip_.*\\.mp4\", \"clip_.*\\.vtt\"]\n",
            "/usr/local/lib/python3.12/dist-packages/gradio/interface.py:415: UserWarning: The `allow_flagging` parameter in `Interface` is deprecated. Use `flagging_mode` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://fadc52037670257f52.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://fadc52037670257f52.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[youtube] Extracting URL: https://youtu.be/BYizgB2FcAQ?si=A7T4_qEFnpq-ph7a\n",
            "[youtube] BYizgB2FcAQ: Downloading webpage\n",
            "[youtube] BYizgB2FcAQ: Downloading android sdkless player API JSON\n",
            "[youtube] BYizgB2FcAQ: Downloading tv client config\n",
            "[youtube] BYizgB2FcAQ: Downloading player c6d7bdc9-main\n",
            "[youtube] BYizgB2FcAQ: Downloading tv player API JSON\n",
            "[youtube] BYizgB2FcAQ: Downloading web safari player API JSON\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: [youtube] Falling back to generic n function search\n",
            "         player = https://www.youtube.com/s/player/c6d7bdc9/player_ias.vflset/en_US/base.js\n",
            "WARNING: [youtube] BYizgB2FcAQ: nsig extraction failed: Some formats may be missing\n",
            "         n = SK5lSexV7wl5b_99 ; player = https://www.youtube.com/s/player/c6d7bdc9/player_ias.vflset/en_US/base.js\n",
            "         Please report this issue on  https://github.com/yt-dlp/yt-dlp/issues?q= , filling out the appropriate issue template. Confirm you are on the latest version using  yt-dlp -U\n",
            "WARNING: [youtube] BYizgB2FcAQ: Some web_safari client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n",
            "WARNING: [youtube] BYizgB2FcAQ: Some web client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[youtube] BYizgB2FcAQ: Downloading m3u8 information\n",
            "[info] BYizgB2FcAQ: Downloading 1 format(s): 96\n",
            "[download] Sleeping 5.00 seconds as required by the site...\n",
            "[hlsnative] Downloading m3u8 manifest\n",
            "[hlsnative] Total fragments: 635\n",
            "[download] Destination: video.mp4\n",
            "[download] 100% of  507.46MiB in 00:00:41 at 12.11MiB/s                  \n",
            "[FixupM3u8] Fixing MPEG-TS in MP4 container of \"video.mp4\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "Device set to use cpu\n",
            "Device set to use cpu\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/pipelines/text_classification.py:111: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://fadc52037670257f52.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    }
  ]
}