{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOX/URzYN6BB7tLrDQEyoXg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prismvale/Podcast-highlights/blob/main/31oct.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "VozpWcJTGJUB",
        "outputId": "ef37fa82-67cd-4c1f-dec6-39e4188a4b3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (4.44.0)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (23.2.1)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.11.0)\n",
            "Requirement already satisfied: fastapi<1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.120.1)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio) (0.6.4)\n",
            "Requirement already satisfied: gradio-client==1.3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.3.0)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.36.0)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (6.5.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.10.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.11.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gradio) (25.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (10.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.11.10)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (6.0.3)\n",
            "Requirement already satisfied: ruff>=0.2.2 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.14.2)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: tomlkit==0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.12.0)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.20.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.15.0)\n",
            "Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.5.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.38.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.3.0->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<13.0,>=10.0 in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.3.0->gradio) (12.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (3.11)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: starlette<0.50.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from fastapi<1.0->gradio) (0.49.1)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from fastapi<1.0->gradio) (0.0.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.24.1->gradio) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.19.3->gradio) (3.20.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.19.3->gradio) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.19.3->gradio) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.19.3->gradio) (1.2.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib~=3.0->gradio) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib~=3.0->gradio) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib~=3.0->gradio) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib~=3.0->gradio) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib~=3.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0->gradio) (0.4.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (8.3.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.4.4)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def reverse_text(text):\n",
        "    return text[::-1]"
      ],
      "metadata": {
        "id": "Muewa3nBGJRR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "# Frontend + backend together\n",
        "demo = gr.Interface(\n",
        "    fn=reverse_text,\n",
        "    inputs=\"text\",\n",
        "    outputs=\"text\",\n",
        "    title=\"🪞 Text Reverser\",\n",
        "    description=\"Type something and watch it reverse instantly!\"\n",
        ")\n",
        "\n",
        "demo.launch(share=True, quiet=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        },
        "id": "AOG5jN9qGJOp",
        "outputId": "624f1682-f6e7-4ac8-bad0-9e2188265a12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/gradio/analytics.py:106: UserWarning: IMPORTANT: You are using gradio version 4.44.0, however version 4.44.1 is available, please upgrade. \n",
            "--------\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on public URL: https://820afaf97c1a7260f8.gradio.live\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://820afaf97c1a7260f8.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "demo.close()\n"
      ],
      "metadata": {
        "id": "qLqLUbkiGJMK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o13Ch8OjGJJi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Me3CC6PcjjwK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RRqqJDeDw52g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NR1Dk24dw55t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fSRuKKVYw6ek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nzx8Ascew6hF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai-whisper yt-dlp webvtt-py transformers torch --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_ql0Ml-qsT5",
        "outputId": "f6a27b60-e627-4acb-975f-31d542083ad8",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/803.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m276.5/803.2 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m803.2/803.2 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.0/176.0 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m57.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# ==============================\n",
        "# 🎥 AI-Powered Auto Clip Generator\n",
        "# ==============================\n",
        "\n",
        "import os\n",
        "import re\n",
        "import subprocess\n",
        "import yt_dlp\n",
        "import whisper\n",
        "import webvtt\n",
        "from transformers import pipeline\n",
        "\n",
        "# ==============================\n",
        "# 1️⃣ USER INPUT\n",
        "# ==============================\n",
        "url = input(\"Enter YouTube URL: \").strip()\n",
        "\n",
        "# ==============================\n",
        "# 🧹 CLEANUP OLD FILES\n",
        "# ==============================\n",
        "def cleanup_old_files():\n",
        "    patterns = [\"video.mp4\", \"video.en.vtt\", \"clip_*.mp4\", \"clip_*.vtt\"]\n",
        "    for pattern in patterns:\n",
        "        for file in [f for f in os.listdir() if re.fullmatch(pattern.replace(\"*\", \".*\"), f)]:\n",
        "            try:\n",
        "                os.remove(file)\n",
        "                print(f\"🧹 Removed old file: {file}\")\n",
        "            except Exception as e:\n",
        "                print(f\"⚠️ Could not remove {file}: {e}\")\n",
        "\n",
        "cleanup_old_files()\n",
        "\n",
        "video_file = \"video.mp4\"\n",
        "sub_file = \"video.en.vtt\"\n",
        "\n",
        "# ==============================\n",
        "# 2️⃣ DOWNLOAD VIDEO\n",
        "# ==============================\n",
        "print(\"⬇️ Downloading video...\")\n",
        "ydl_opts = {\"format\": \"mp4\", \"outtmpl\": \"video.%(ext)s\"}\n",
        "with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "    ydl.download([url])\n",
        "\n",
        "# ==============================\n",
        "# 3️⃣ GENERATE SUBTITLES USING WHISPER\n",
        "# ==============================\n",
        "print(\"🎤 Generating subtitles with Whisper...\")\n",
        "model = whisper.load_model(\"tiny\")\n",
        "result = model.transcribe(video_file)\n",
        "\n",
        "with open(sub_file, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(\"WEBVTT\\n\\n\")\n",
        "    for i, seg in enumerate(result[\"segments\"]):\n",
        "        start, end, text = seg[\"start\"], seg[\"end\"], seg[\"text\"].strip()\n",
        "        def sec_to_vtt(s):\n",
        "            h = int(s // 3600)\n",
        "            m = int((s % 3600) // 60)\n",
        "            sec = s % 60\n",
        "            return f\"{h:02}:{m:02}:{sec:06.3f}\"\n",
        "        f.write(f\"{i+1}\\n{sec_to_vtt(start)} --> {sec_to_vtt(end)}\\n{text}\\n\\n\")\n",
        "\n",
        "print(\"✅ Subtitles saved as video.en.vtt\")\n",
        "\n",
        "\n",
        "\n",
        "# ==============================\n",
        "# 4️⃣ GROUP INTO SENTENCE CHUNKS\n",
        "# ==============================\n",
        "print(\"🧩 Creating text chunks...\")\n",
        "grouped_chunks = []\n",
        "current_chunk, chunk_start, chunk_end = [], None, None\n",
        "max_chunk_duration, min_chunk_duration = 25.0, 10.0\n",
        "\n",
        "for caption in webvtt.read(sub_file):\n",
        "    start_sec = sum(float(x) * 60 ** i for i, x in enumerate(reversed(caption.start.split(\":\"))))\n",
        "    end_sec = sum(float(x) * 60 ** i for i, x in enumerate(reversed(caption.end.split(\":\"))))\n",
        "\n",
        "    if chunk_start is None:\n",
        "        chunk_start = start_sec\n",
        "\n",
        "    sentences = [s.strip() for s in re.split(r'(?<=[.!?]) +', caption.text) if s.strip()]\n",
        "\n",
        "    for sentence in sentences:\n",
        "        current_chunk.append(sentence)\n",
        "        chunk_end = end_sec\n",
        "\n",
        "        # Only create chunk if max duration exceeded\n",
        "        if chunk_start is not None and chunk_end is not None and (chunk_end - chunk_start >= max_chunk_duration):\n",
        "            if grouped_chunks and (chunk_end - chunk_start < min_chunk_duration):\n",
        "                # Merge with previous chunk safely\n",
        "                grouped_chunks[-1][\"end\"] = chunk_end\n",
        "                grouped_chunks[-1][\"text\"] += \" \" + \" \".join(current_chunk)\n",
        "            else:\n",
        "                # Create a new chunk\n",
        "                grouped_chunks.append({\n",
        "                    \"start\": chunk_start,\n",
        "                    \"end\": chunk_end,\n",
        "                    \"text\": \" \".join(current_chunk)\n",
        "                })\n",
        "            # Reset for next chunk\n",
        "            current_chunk, chunk_start, chunk_end = [], None, None\n",
        "\n",
        "# Handle leftover sentences at the end\n",
        "if current_chunk:\n",
        "    if chunk_start is not None and chunk_end is not None:\n",
        "        if grouped_chunks and (chunk_end - chunk_start < min_chunk_duration):\n",
        "            grouped_chunks[-1][\"end\"] = chunk_end\n",
        "            grouped_chunks[-1][\"text\"] += \" \" + \" \".join(current_chunk)\n",
        "        else:\n",
        "            grouped_chunks.append({\n",
        "                \"start\": chunk_start,\n",
        "                \"end\": chunk_end,\n",
        "                \"text\": \" \".join(current_chunk)\n",
        "            })\n",
        "\n",
        "print(f\"✅ Total chunks created: {len(grouped_chunks)}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ==============================\n",
        "# 5️⃣ ANALYZE EMOTION + SENTIMENT\n",
        "# ==============================\n",
        "print(\"🧠 Analyzing emotion and sentiment...\")\n",
        "sentiment_model = pipeline(\"sentiment-analysis\", model=\"cardiffnlp/twitter-roberta-base-sentiment\")\n",
        "emotion_model = pipeline(\"text-classification\",\n",
        "                         model=\"joeddav/distilbert-base-uncased-go-emotions-student\",\n",
        "                         return_all_scores=True)\n",
        "\n",
        "scored_chunks = []\n",
        "for chunk in grouped_chunks:\n",
        "    text = chunk[\"text\"]\n",
        "    sentiment = sentiment_model(text[:512])[0]\n",
        "    emotions = emotion_model(text[:512])[0]\n",
        "    top_emotion = max(emotions, key=lambda x: x['score'])\n",
        "    score = sentiment['score'] * 5\n",
        "    if top_emotion['label'] in [\"joy\", \"excitement\", \"anger\", \"sadness\"]:\n",
        "        score += top_emotion['score'] * 5\n",
        "    scored_chunks.append({\n",
        "        \"start\": chunk[\"start\"],\n",
        "        \"end\": chunk[\"end\"],\n",
        "        \"text\": text,\n",
        "        \"sentiment\": sentiment['label'],\n",
        "        \"emotion\": top_emotion['label'],\n",
        "        \"score\": score\n",
        "    })\n",
        "\n",
        "# ==============================\n",
        "# 6️⃣ SELECT TOP 3 CLIPS\n",
        "# ==============================\n",
        "scored_chunks = sorted(scored_chunks, key=lambda x: x[\"score\"], reverse=True)\n",
        "top3 = scored_chunks[:3]\n",
        "\n",
        "print(\"\\n🔥 Top 3 Engaging Moments:\")\n",
        "for i, c in enumerate(top3, 1):\n",
        "    print(f\"\\n--- Clip {i} ---\")\n",
        "    print(f\"Time: {c['start']:.2f}s → {c['end']:.2f}s\")\n",
        "    print(f\"Emotion: {c['emotion']} | Sentiment: {c['sentiment']} | Score: {c['score']:.2f}\")\n",
        "    print(f\"Text: {c['text'][:150]}...\")\n",
        "\n",
        "# ==============================\n",
        "# 7️⃣ EXTRACT CLIPS + SUBTITLES\n",
        "# ==============================\n",
        "print(\"\\n✂️ Extracting top 3 clips...\")\n",
        "captions = list(webvtt.read(sub_file))\n",
        "\n",
        "def format_time(seconds):\n",
        "    h = int(seconds // 3600)\n",
        "    m = int((seconds % 3600) // 60)\n",
        "    s = seconds % 60\n",
        "    return f\"{h:02d}:{m:02d}:{s:06.3f}\".replace('.', ',')\n",
        "\n",
        "for i, clip in enumerate(top3, 1):\n",
        "    start, end = clip[\"start\"], clip[\"end\"]\n",
        "    out_video, out_sub = f\"clip_{i}.mp4\", f\"clip_{i}.vtt\"\n",
        "\n",
        "    # Extract video\n",
        "    cmd = [\"ffmpeg\", \"-y\", \"-i\", video_file, \"-ss\", str(start), \"-to\", str(end), \"-c\", \"copy\", out_video]\n",
        "    subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "\n",
        "    # Extract subtitles for the clip\n",
        "    selected = []\n",
        "    for c in captions:\n",
        "        start_sec = sum(float(x) * 60 ** i for i, x in enumerate(reversed(c.start.split(\":\"))))\n",
        "        end_sec = sum(float(x) * 60 ** i for i, x in enumerate(reversed(c.end.split(\":\"))))\n",
        "        if start_sec >= start and end_sec <= end:\n",
        "            new_start, new_end = start_sec - start, end_sec - start\n",
        "            selected.append(f\"{format_time(new_start)} --> {format_time(new_end)}\\n{c.text}\\n\")\n",
        "\n",
        "    with open(out_sub, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(\"WEBVTT\\n\\n\" + \"\\n\".join(selected))\n",
        "\n",
        "    print(f\"✅ Saved: {out_video} + {out_sub}\")\n",
        "\n",
        "print(\"\\n🎉 Done! Your top 3 clips and subtitles are ready.\")\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "9VZgroSMjjyo",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JPyuAqIMQoyg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "!pip install openai-whisper yt-dlp webvtt-py transformers torch gradio --quiet\n",
        "\n",
        "# ==============================\n",
        "# 🎥 AI-Powered Auto Clip Generator (Colab + Gradio Frontend)\n",
        "# ==============================\n",
        "import os\n",
        "import re\n",
        "import subprocess\n",
        "import yt_dlp\n",
        "import whisper\n",
        "import webvtt\n",
        "import gradio as gr\n",
        "from transformers import pipeline\n",
        "\n",
        "# ==============================\n",
        "# ⚙️ Core Logic Function\n",
        "# ==============================\n",
        "def process_youtube_video(url):\n",
        "    try:\n",
        "        # ---------- CLEANUP ----------\n",
        "        patterns = [\"video.mp4\", \"video.en.vtt\", \"clip_.*\\.mp4\", \"clip_.*\\.vtt\"]\n",
        "        for pattern in patterns:\n",
        "            for file in [f for f in os.listdir() if re.fullmatch(pattern.replace(\"*\", \".*\"), f)]:\n",
        "                try:\n",
        "                    os.remove(file)\n",
        "                except Exception:\n",
        "                    pass\n",
        "\n",
        "        video_file = \"video.mp4\"\n",
        "        sub_file = \"video.en.vtt\"\n",
        "\n",
        "        # ---------- DOWNLOAD ----------\n",
        "        ydl_opts = {\"format\": \"mp4\", \"outtmpl\": \"video.%(ext)s\"}\n",
        "        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "            ydl.download([url])\n",
        "\n",
        "        # ---------- WHISPER ----------\n",
        "        model = whisper.load_model(\"tiny\")\n",
        "        result = model.transcribe(video_file)\n",
        "\n",
        "        with open(sub_file, \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(\"WEBVTT\\n\\n\")\n",
        "            for i, seg in enumerate(result[\"segments\"]):\n",
        "                start, end, text = seg[\"start\"], seg[\"end\"], seg[\"text\"].strip()\n",
        "                def sec_to_vtt(s):\n",
        "                    h = int(s // 3600)\n",
        "                    m = int((s % 3600) // 60)\n",
        "                    sec = s % 60\n",
        "                    return f\"{h:02}:{m:02}:{sec:06.3f}\"\n",
        "                f.write(f\"{i+1}\\n{sec_to_vtt(start)} --> {sec_to_vtt(end)}\\n{text}\\n\\n\")\n",
        "\n",
        "        # ---------- GROUP CHUNKS ----------\n",
        "        grouped_chunks = []\n",
        "        current_chunk, chunk_start, chunk_end = [], None, None\n",
        "        max_chunk_duration, min_chunk_duration = 25.0, 10.0\n",
        "\n",
        "        for caption in webvtt.read(sub_file):\n",
        "            start_sec = sum(float(x) * 60 ** i for i, x in enumerate(reversed(caption.start.split(\":\"))))\n",
        "            end_sec = sum(float(x) * 60 ** i for i, x in enumerate(reversed(caption.end.split(\":\"))))\n",
        "\n",
        "            if chunk_start is None:\n",
        "                chunk_start = start_sec\n",
        "\n",
        "            sentences = [s.strip() for s in re.split(r'(?<=[.!?]) +', caption.text) if s.strip()]\n",
        "\n",
        "            for sentence in sentences:\n",
        "                current_chunk.append(sentence)\n",
        "                chunk_end = end_sec\n",
        "                if chunk_start is not None and chunk_end is not None and (chunk_end - chunk_start >= max_chunk_duration):\n",
        "                    if grouped_chunks and (chunk_end - chunk_start < min_chunk_duration):\n",
        "                        grouped_chunks[-1][\"end\"] = chunk_end\n",
        "                        grouped_chunks[-1][\"text\"] += \" \" + \" \".join(current_chunk)\n",
        "                    else:\n",
        "                        grouped_chunks.append({\n",
        "                            \"start\": chunk_start,\n",
        "                            \"end\": chunk_end,\n",
        "                            \"text\": \" \".join(current_chunk)\n",
        "                        })\n",
        "                    current_chunk, chunk_start, chunk_end = [], None, None\n",
        "\n",
        "        if current_chunk:\n",
        "            if chunk_start is not None and chunk_end is not None:\n",
        "                if grouped_chunks and (chunk_end - chunk_start < min_chunk_duration):\n",
        "                    grouped_chunks[-1][\"end\"] = chunk_end\n",
        "                    grouped_chunks[-1][\"text\"] += \" \" + \" \".join(current_chunk)\n",
        "                else:\n",
        "                    grouped_chunks.append({\n",
        "                        \"start\": chunk_start,\n",
        "                        \"end\": chunk_end,\n",
        "                        \"text\": \" \".join(current_chunk)\n",
        "                    })\n",
        "\n",
        "        # ---------- ANALYSIS ----------\n",
        "        sentiment_model = pipeline(\"sentiment-analysis\", model=\"cardiffnlp/twitter-roberta-base-sentiment\")\n",
        "        emotion_model = pipeline(\"text-classification\",\n",
        "                                 model=\"joeddav/distilbert-base-uncased-go-emotions-student\",\n",
        "                                 return_all_scores=True)\n",
        "\n",
        "        scored_chunks = []\n",
        "        for chunk in grouped_chunks:\n",
        "            text = chunk[\"text\"]\n",
        "            sentiment = sentiment_model(text[:512])[0]\n",
        "            emotions = emotion_model(text[:512])[0]\n",
        "            top_emotion = max(emotions, key=lambda x: x['score'])\n",
        "            score = sentiment['score'] * 5\n",
        "            if top_emotion['label'] in [\"joy\", \"excitement\", \"anger\", \"sadness\"]:\n",
        "                score += top_emotion['score'] * 5\n",
        "            scored_chunks.append({\n",
        "                \"start\": chunk[\"start\"],\n",
        "                \"end\": chunk[\"end\"],\n",
        "                \"text\": text,\n",
        "                \"sentiment\": sentiment['label'],\n",
        "                \"emotion\": top_emotion['label'],\n",
        "                \"score\": score\n",
        "            })\n",
        "\n",
        "        # ---------- SELECT TOP 3 ----------\n",
        "        scored_chunks = sorted(scored_chunks, key=lambda x: x[\"score\"], reverse=True)\n",
        "        top3 = scored_chunks[:3]\n",
        "\n",
        "        result_text = \"🔥 **Top 3 Engaging Moments:**\\n\\n\"\n",
        "        #for i, c in enumerate(top3, 1):\n",
        "            #result_text += f\"### 🎬 Clip {i}\\n\"\n",
        "            #result_text += f\"- Time: {c['start']:.2f}s → {c['end']:.2f}s\\n\"\n",
        "            #result_text += f\"- Emotion: {c['emotion']} | Sentiment: {c['sentiment']} | Score: {c['score']:.2f}\\n\"\n",
        "            #result_text += f\"- Text: {c['text'][:150]}...\\n\\n\"\n",
        "\n",
        "        # ---------- EXTRACT CLIPS ----------\n",
        "        captions = list(webvtt.read(sub_file))\n",
        "        def format_time(seconds):\n",
        "            h = int(seconds // 3600)\n",
        "            m = int((seconds % 3600) // 60)\n",
        "            s = seconds % 60\n",
        "            return f\"{h:02d}:{m:02d}:{s:06.3f}\".replace('.', ',')\n",
        "\n",
        "        video_files = []\n",
        "        for i, clip in enumerate(top3, 1):\n",
        "            start, end = clip[\"start\"], clip[\"end\"]\n",
        "            out_video, out_sub = f\"clip_{i}.mp4\", f\"clip_{i}.vtt\"\n",
        "            cmd = [\"ffmpeg\", \"-y\", \"-i\", video_file, \"-ss\", str(start), \"-to\", str(end), \"-c\", \"copy\", out_video]\n",
        "            subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "            video_files.append(out_video)\n",
        "\n",
        "            selected = []\n",
        "            for c in captions:\n",
        "                start_sec = sum(float(x) * 60 ** i for i, x in enumerate(reversed(c.start.split(\":\"))))\n",
        "                end_sec = sum(float(x) * 60 ** i for i, x in enumerate(reversed(c.end.split(\":\"))))\n",
        "                if start_sec >= start and end_sec <= end:\n",
        "                    new_start, new_end = start_sec - start, end_sec - start\n",
        "                    selected.append(f\"{format_time(new_start)} --> {format_time(new_end)}\\n{c.text}\\n\")\n",
        "\n",
        "            with open(out_sub, \"w\", encoding=\"utf-8\") as f:\n",
        "                f.write(\"WEBVTT\\n\\n\" + \"\\n\".join(selected))\n",
        "\n",
        "        return result_text, video_files[0] if len(video_files) > 0 else None, video_files[1] if len(video_files) > 1 else None, video_files[2] if len(video_files) > 2 else None\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"⚠️ Error: {e}\", None, None, None\n",
        "\n",
        "# ==============================\n",
        "# 🎨 Gradio UI\n",
        "# ==============================\n",
        "demo = gr.Interface(\n",
        "    fn=process_youtube_video,\n",
        "    inputs=gr.Textbox(label=\"Enter YouTube URL\"),\n",
        "    outputs=[\n",
        "        gr.Markdown(label=\"Results\"),\n",
        "        gr.Video(label=\"Clip 1\"),\n",
        "        gr.Video(label=\"Clip 2\"),\n",
        "        gr.Video(label=\"Clip 3\")\n",
        "    ],\n",
        "    title=\"🎥 AI Auto Clip Generator\",\n",
        "    description=\"Automatically extracts top 3 emotional or engaging clips from a YouTube video using Whisper + NLP sentiment/emotion analysis.\",\n",
        "    allow_flagging=\"never\"\n",
        ")\n",
        "\n",
        "demo.launch(debug=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "cellView": "form",
        "id": "WlCzDHDyClYs",
        "outputId": "360b9c47-7a82-4bed-9941-5665c310c83a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:22: SyntaxWarning: invalid escape sequence '\\.'\n",
            "<>:22: SyntaxWarning: invalid escape sequence '\\.'\n",
            "<>:22: SyntaxWarning: invalid escape sequence '\\.'\n",
            "<>:22: SyntaxWarning: invalid escape sequence '\\.'\n",
            "/tmp/ipython-input-98566741.py:22: SyntaxWarning: invalid escape sequence '\\.'\n",
            "  patterns = [\"video.mp4\", \"video.en.vtt\", \"clip_.*\\.mp4\", \"clip_.*\\.vtt\"]\n",
            "/tmp/ipython-input-98566741.py:22: SyntaxWarning: invalid escape sequence '\\.'\n",
            "  patterns = [\"video.mp4\", \"video.en.vtt\", \"clip_.*\\.mp4\", \"clip_.*\\.vtt\"]\n",
            "/usr/local/lib/python3.12/dist-packages/gradio/interface.py:415: UserWarning: The `allow_flagging` parameter in `Interface` is deprecated. Use `flagging_mode` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://fadc52037670257f52.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://fadc52037670257f52.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[youtube] Extracting URL: https://youtu.be/BYizgB2FcAQ?si=A7T4_qEFnpq-ph7a\n",
            "[youtube] BYizgB2FcAQ: Downloading webpage\n",
            "[youtube] BYizgB2FcAQ: Downloading android sdkless player API JSON\n",
            "[youtube] BYizgB2FcAQ: Downloading tv client config\n",
            "[youtube] BYizgB2FcAQ: Downloading player c6d7bdc9-main\n",
            "[youtube] BYizgB2FcAQ: Downloading tv player API JSON\n",
            "[youtube] BYizgB2FcAQ: Downloading web safari player API JSON\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: [youtube] Falling back to generic n function search\n",
            "         player = https://www.youtube.com/s/player/c6d7bdc9/player_ias.vflset/en_US/base.js\n",
            "WARNING: [youtube] BYizgB2FcAQ: nsig extraction failed: Some formats may be missing\n",
            "         n = SK5lSexV7wl5b_99 ; player = https://www.youtube.com/s/player/c6d7bdc9/player_ias.vflset/en_US/base.js\n",
            "         Please report this issue on  https://github.com/yt-dlp/yt-dlp/issues?q= , filling out the appropriate issue template. Confirm you are on the latest version using  yt-dlp -U\n",
            "WARNING: [youtube] BYizgB2FcAQ: Some web_safari client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n",
            "WARNING: [youtube] BYizgB2FcAQ: Some web client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[youtube] BYizgB2FcAQ: Downloading m3u8 information\n",
            "[info] BYizgB2FcAQ: Downloading 1 format(s): 96\n",
            "[download] Sleeping 5.00 seconds as required by the site...\n",
            "[hlsnative] Downloading m3u8 manifest\n",
            "[hlsnative] Total fragments: 635\n",
            "[download] Destination: video.mp4\n",
            "[download] 100% of  507.46MiB in 00:00:41 at 12.11MiB/s                  \n",
            "[FixupM3u8] Fixing MPEG-TS in MP4 container of \"video.mp4\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "Device set to use cpu\n",
            "Device set to use cpu\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/pipelines/text_classification.py:111: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://fadc52037670257f52.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    }
  ]
}